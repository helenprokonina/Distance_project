{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(point, rectangle):\n",
    "    # image = np.zeros((100, 100), dtype='uint8')\n",
    "    (x0, y0) = point\n",
    "    (x1,y1) = rectangle[:2]\n",
    "    (x2,y2) = rectangle[2:]\n",
    "    \n",
    "    #minimum distance is in some corner point\n",
    "    if x0>=x2 and y0<=y1:\n",
    "        d=np.sqrt((x2-x0)**2+(y1-y0)**2)\n",
    "        d_coord = [x0,y0, x2,y1]\n",
    "    if x0<=x1 and y0<=y1:\n",
    "        d=np.sqrt((x1-x0)**2+(y1-y0)**2)\n",
    "        d_coord = [x0,y0, x1,y1]  \n",
    "    if x0<=x1 and y0>=y2:\n",
    "        d=np.sqrt((x1-x0)**2+(y2-y0)**2)\n",
    "        d_coord = [x0,y0, x1,y2]    \n",
    "    if x0>=x2 and y0>=y2:\n",
    "        d=np.sqrt((x2-x0)**2+(y2-y0)**2)\n",
    "        d_coord = [x0,y0, x2,y2]     \n",
    "     #minimum distance is on the edge: draw perpendicular to that edge from (x0,y0)\n",
    "    if x0>=x1 and x0<=x2 and y0>=y2:\n",
    "        d=y0-y2\n",
    "        d_coord = [x0,y0, x0,y2] \n",
    "    if x0>=x1 and x0<=x2 and y0<=y1:\n",
    "        d=y1-y0\n",
    "        d_coord = [x0,y0, x0,y1]  \n",
    "    if y0>=y1 and y0<=y2 and x0>=x2:\n",
    "        d=x0-x2\n",
    "        d_coord = [x0,y0, x2,y0] \n",
    "    if y0>=y1 and y0<=y2 and x0<=x1:\n",
    "        d=x1-x0\n",
    "        d_coord = [x0,y0, x1,y0]      \n",
    "        \n",
    "    #draw distance\n",
    "    # cv2.rectangle(image, (x1, y1), (x2, y2), color=(255,0,0), thickness=1)\n",
    "    # cv2.circle(image, (x0,y0), radius=0, color=(255, 0, 0), thickness=-1)\n",
    "    # cv2.line(image, d_coord[:2], d_coord[2:], color = (255, 255, 255), thickness=1)\n",
    "    # plt.imshow(image)\n",
    "    # plt.axis(\"off\")\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.12205669071391\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = distance([40,6], [50, 50, 90, 70])\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(rect1, rect2):\n",
    "    # take senter of person as a point\n",
    "    (x0, y0) = int((rect1[0]+rect1[2])/2), int((rect1[1]+rect1[3])/2)\n",
    "    (x1,y1) = rect2[:2]\n",
    "    (x2,y2) = rect2[2:]\n",
    "    \n",
    "    d=0\n",
    "    \n",
    "    #minimum distance is in some corner point\n",
    "    if x0>=x2 and y0<=y1:\n",
    "        d=np.sqrt((x2-x0)**2+(y1-y0)**2)\n",
    "        d_coord = [x0,y0, x2,y1]\n",
    "    if x0<=x1 and y0<=y1:\n",
    "        d=np.sqrt((x1-x0)**2+(y1-y0)**2)\n",
    "        d_coord = [x0,y0, x1,y1]  \n",
    "    if x0<=x1 and y0>=y2:\n",
    "        d=np.sqrt((x1-x0)**2+(y2-y0)**2)\n",
    "        d_coord = [x0,y0, x1,y2]    \n",
    "    if x0>=x2 and y0>=y2:\n",
    "        d=np.sqrt((x2-x0)**2+(y2-y0)**2)\n",
    "        d_coord = [x0,y0, x2,y2]     \n",
    "     #minimum distance is on the edge: draw perpendicular to that edge from (x0,y0)\n",
    "    if x0>=x1 and x0<=x2 and y0>=y2:\n",
    "        d=y0-y2\n",
    "        d_coord = [x0,y0, x0,y2] \n",
    "    if x0>=x1 and x0<=x2 and y0<=y1:\n",
    "        d=y1-y0\n",
    "        d_coord = [x0,y0, x0,y1]  \n",
    "    if y0>=y1 and y0<=y2 and x0>=x2:\n",
    "        d=x0-x2\n",
    "        d_coord = [x0,y0, x2,y0] \n",
    "    if y0>=y1 and y0<=y2 and x0<=x1:\n",
    "        d=x1-x0\n",
    "        d_coord = [x0,y0, x1,y0]      \n",
    "        \n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 6 persons, 5 cars, 1 truck, 2 traffic lights, 665.1ms\n",
      "Speed: 8.0ms preprocess, 665.1ms inference, 12.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 5 cars, 1 truck, 1 traffic light, 182.4ms\n",
      "Speed: 5.5ms preprocess, 182.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 4 cars, 1 truck, 1 traffic light, 224.3ms\n",
      "Speed: 2.7ms preprocess, 224.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 4 cars, 1 truck, 1 traffic light, 159.0ms\n",
      "Speed: 4.0ms preprocess, 159.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 4 cars, 1 truck, 2 traffic lights, 160.4ms\n",
      "Speed: 6.0ms preprocess, 160.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 5 cars, 1 truck, 2 traffic lights, 152.6ms\n",
      "Speed: 13.5ms preprocess, 152.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 4 cars, 1 truck, 3 traffic lights, 145.0ms\n",
      "Speed: 4.0ms preprocess, 145.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 4 cars, 1 truck, 2 traffic lights, 130.8ms\n",
      "Speed: 6.0ms preprocess, 130.8ms inference, 16.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 4 cars, 1 truck, 1 traffic light, 155.7ms\n",
      "Speed: 3.9ms preprocess, 155.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 4 cars, 1 truck, 2 traffic lights, 141.1ms\n",
      "Speed: 2.0ms preprocess, 141.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 5 cars, 1 truck, 2 traffic lights, 147.0ms\n",
      "Speed: 5.0ms preprocess, 147.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 4 cars, 1 truck, 2 traffic lights, 159.6ms\n",
      "Speed: 3.0ms preprocess, 159.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 5 cars, 1 truck, 3 traffic lights, 127.2ms\n",
      "Speed: 7.0ms preprocess, 127.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 4 cars, 1 truck, 3 traffic lights, 150.4ms\n",
      "Speed: 11.2ms preprocess, 150.4ms inference, 11.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 4 cars, 1 truck, 4 traffic lights, 139.3ms\n",
      "Speed: 3.8ms preprocess, 139.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 4 cars, 1 truck, 4 traffic lights, 161.3ms\n",
      "Speed: 5.0ms preprocess, 161.3ms inference, 11.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 4 cars, 1 truck, 3 traffic lights, 139.9ms\n",
      "Speed: 4.0ms preprocess, 139.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 5 cars, 1 truck, 3 traffic lights, 150.3ms\n",
      "Speed: 5.0ms preprocess, 150.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 6 cars, 1 truck, 3 traffic lights, 144.0ms\n",
      "Speed: 0.0ms preprocess, 144.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 6 cars, 3 traffic lights, 145.3ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 4.0ms preprocess, 145.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 8 persons, 5 cars, 3 traffic lights, 162.8ms\n",
      "Speed: 3.0ms preprocess, 162.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 5 cars, 3 traffic lights, 152.5ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 4.0ms preprocess, 152.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 4 cars, 3 traffic lights, 147.3ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 3.0ms preprocess, 147.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 6 cars, 3 traffic lights, 161.2ms\n",
      "Speed: 1.6ms preprocess, 161.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 8 persons, 5 cars, 3 traffic lights, 157.5ms\n",
      "Speed: 0.0ms preprocess, 157.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 6 cars, 3 traffic lights, 143.4ms\n",
      "Speed: 3.5ms preprocess, 143.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 8 persons, 6 cars, 3 traffic lights, 172.2ms\n",
      "Speed: 5.1ms preprocess, 172.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 5 cars, 3 traffic lights, 152.2ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 4.3ms preprocess, 152.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 8 persons, 5 cars, 3 traffic lights, 152.9ms\n",
      "Speed: 4.0ms preprocess, 152.9ms inference, 11.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 6 cars, 1 truck, 4 traffic lights, 140.7ms\n",
      "Speed: 9.0ms preprocess, 140.7ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 6 cars, 1 truck, 3 traffic lights, 139.5ms\n",
      "Speed: 4.0ms preprocess, 139.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 9 persons, 4 cars, 1 truck, 3 traffic lights, 146.4ms\n",
      "Speed: 1.9ms preprocess, 146.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 4 cars, 1 truck, 3 traffic lights, 130.7ms\n",
      "Speed: 3.9ms preprocess, 130.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 4 cars, 1 truck, 3 traffic lights, 143.4ms\n",
      "Speed: 0.0ms preprocess, 143.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 5 cars, 3 traffic lights, 171.0ms\n",
      "Speed: 0.6ms preprocess, 171.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 9 persons, 4 cars, 3 traffic lights, 166.8ms\n",
      "Speed: 0.6ms preprocess, 166.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 4 cars, 3 traffic lights, 139.8ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 4.5ms preprocess, 139.8ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 4 cars, 1 truck, 5 traffic lights, 147.9ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 4.1ms preprocess, 147.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 5 cars, 1 truck, 5 traffic lights, 143.1ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 4.6ms preprocess, 143.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 5 cars, 4 traffic lights, 147.1ms\n",
      "Speed: 3.2ms preprocess, 147.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 5 cars, 1 truck, 3 traffic lights, 135.5ms\n",
      "Speed: 5.7ms preprocess, 135.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 5 cars, 2 traffic lights, 172.8ms\n",
      "Speed: 1.8ms preprocess, 172.8ms inference, 12.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 5 cars, 1 truck, 1 traffic light, 124.7ms\n",
      "Speed: 3.7ms preprocess, 124.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 5 cars, 1 truck, 2 traffic lights, 130.9ms\n",
      "Speed: 3.2ms preprocess, 130.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 5 cars, 1 truck, 3 traffic lights, 156.9ms\n",
      "Speed: 2.5ms preprocess, 156.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 5 cars, 1 truck, 3 traffic lights, 125.5ms\n",
      "Speed: 4.0ms preprocess, 125.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 5 cars, 1 truck, 4 traffic lights, 131.5ms\n",
      "Speed: 5.1ms preprocess, 131.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 4 cars, 1 truck, 4 traffic lights, 138.0ms\n",
      "Speed: 6.2ms preprocess, 138.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 4 cars, 4 traffic lights, 144.4ms\n",
      "Speed: 3.0ms preprocess, 144.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 4 cars, 3 traffic lights, 143.2ms\n",
      "Speed: 4.2ms preprocess, 143.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 4 cars, 4 traffic lights, 130.3ms\n",
      "Speed: 3.3ms preprocess, 130.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 4 cars, 1 truck, 4 traffic lights, 160.5ms\n",
      "Speed: 4.4ms preprocess, 160.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 cars, 1 truck, 5 traffic lights, 160.9ms\n",
      "Speed: 4.3ms preprocess, 160.9ms inference, 13.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 4 cars, 1 truck, 4 traffic lights, 156.9ms\n",
      "Speed: 4.0ms preprocess, 156.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 3 cars, 1 truck, 4 traffic lights, 210.3ms\n",
      "Speed: 4.0ms preprocess, 210.3ms inference, 14.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 6 persons, 4 cars, 1 truck, 4 traffic lights, 197.8ms\n",
      "Speed: 4.1ms preprocess, 197.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4 cars, 1 truck, 4 traffic lights, 162.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 4.0ms preprocess, 162.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 9 persons, 4 cars, 1 truck, 4 traffic lights, 200.9ms\n",
      "Speed: 4.5ms preprocess, 200.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 4 cars, 5 traffic lights, 177.7ms\n",
      "Speed: 5.7ms preprocess, 177.7ms inference, 15.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 9 persons, 4 cars, 1 truck, 4 traffic lights, 151.2ms\n",
      "Speed: 3.2ms preprocess, 151.2ms inference, 15.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 4 cars, 1 truck, 3 traffic lights, 134.9ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 3.2ms preprocess, 134.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 4 cars, 2 traffic lights, 142.8ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 4.1ms preprocess, 142.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 4 cars, 3 traffic lights, 149.2ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 3.1ms preprocess, 149.2ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 4 cars, 1 truck, 4 traffic lights, 140.5ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 3.4ms preprocess, 140.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 4 cars, 1 truck, 4 traffic lights, 158.3ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 3.7ms preprocess, 158.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 4 cars, 4 traffic lights, 147.2ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 4.0ms preprocess, 147.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 4 cars, 4 traffic lights, 132.7ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 4.7ms preprocess, 132.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 10 persons, 4 cars, 4 traffic lights, 210.0ms\n",
      "Speed: 6.3ms preprocess, 210.0ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 4 cars, 4 traffic lights, 142.2ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 3.0ms preprocess, 142.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 9 persons, 4 cars, 4 traffic lights, 166.9ms\n",
      "Speed: 4.2ms preprocess, 166.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 4 cars, 5 traffic lights, 148.6ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 3.0ms preprocess, 148.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 4 cars, 5 traffic lights, 159.1ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 3.4ms preprocess, 159.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 5 cars, 3 traffic lights, 164.8ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 4.3ms preprocess, 164.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 bicycle, 4 cars, 3 traffic lights, 145.9ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 5.8ms preprocess, 145.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 4 cars, 1 truck, 3 traffic lights, 146.4ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 3.0ms preprocess, 146.4ms inference, 14.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 4 cars, 4 traffic lights, 128.6ms\n",
      "Speed: 3.3ms preprocess, 128.6ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"videos/traffic2.mp4\")\n",
    "\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    \n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    results = model.predict(img)\n",
    "    people_boxes = []\n",
    "    cars_boxes = []\n",
    "    \n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes: \n",
    "            b = box.xyxy[0].numpy().astype(\"int\") # get box coordinates in (top, left, bottom, right) format\n",
    "            c = box.cls\n",
    "            if model.names[int(c)]==\"person\":\n",
    "                people_boxes.append(b)\n",
    "            if model.names[int(c)] in [\"car\", \"truck\"]:\n",
    "                cars_boxes.append(b)  \n",
    "            \n",
    "                           \n",
    "            # print(b)\n",
    "            # print(model.names[int(c)])\n",
    "            if model.names[int(c)] in ['person', 'car', \"truck\"]:\n",
    "                cv2.rectangle(frame, b[:2], b[2:], color = (255, 0, 0), thickness=2)\n",
    "                \n",
    "    # print(cars_boxes)            \n",
    "    # d = get_distance(cars_boxes[0], cars_boxes[1])\n",
    "    # print(d)\n",
    "                \n",
    "    for person in people_boxes:\n",
    "        for car in cars_boxes:\n",
    "            if get_distance(person, car)<10:\n",
    "                print(get_distance(person, car))\n",
    "                cv2.rectangle(frame, person[:2], person[2:], color = (0, 0, 255), thickness=3) \n",
    "                cv2.rectangle(frame, car[:2], car[2:], color = (0, 0, 255), thickness=3)\n",
    "                cv2.putText(frame, \"ALARM!\", (20, 50), cv2.FONT_HERSHEY_SIMPLEX , fontScale = 1, color=(0, 0, 255), thickness=5) \n",
    "                            \n",
    "    imS = cv2.resize(frame, (960, 540))        \n",
    "    cv2.imshow('YOLO V8 Detection', imS)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
